{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7b7199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch-size BATCH_SIZE] [--epochs EPOCHS]\n",
      "                             [--lr LR] [--dropout DROPOUT]\n",
      "                             [--data-dir DATA_DIR] [--save-dir SAVE_DIR]\n",
      "                             [--no-cuda]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/run/user/1000/jupyter/runtime/kernel-v3ee74f6bbd386df6471721ad79a4bf81eacd1228c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toybot/anaconda3/envs/gvenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class FashionCNN(nn.Module):\n",
    "    \"\"\"Simple CNN for Fashion‑MNIST (28×28 grayscale, 10 classes).\"\"\"\n",
    "\n",
    "    def __init__(self, dropout: float = 0.25):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # (N, 1, 28, 28) → (N, 32, 28, 28)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # (N, 32, 14, 14)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # (N, 64, 14, 14)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # (N, 64, 7, 7)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),  # (N, 64*7*7)\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "def train_one_epoch(model: nn.Module, loader: DataLoader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for inputs, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=\"Validation\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def save_checkpoint(model: nn.Module, path: str):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"\\nModel checkpoint saved to {path}\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Train a CNN on Fashion‑MNIST with PyTorch\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=128)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    parser.add_argument(\"--dropout\", type=float, default=0.25)\n",
    "    parser.add_argument(\"--data-dir\", type=str, default=\"./data\")\n",
    "    parser.add_argument(\"--save-dir\", type=str, default=\"./checkpoints\")\n",
    "    parser.add_argument(\"--no-cuda\", action=\"store_true\", help=\"disable CUDA training\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    use_cuda = torch.cuda.is_available() and not args.no_cuda\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Data transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "\n",
    "    # Dataset & loaders\n",
    "    train_dataset = datasets.FashionMNIST(root=args.data_dir, train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.FashionMNIST(root=args.data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=use_cuda)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=use_cuda)\n",
    "\n",
    "    # Model, criterion, optimizer\n",
    "    model = FashionCNN(dropout=args.dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{args.epochs}\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Train loss: {train_loss:.4f} | Train acc: {train_acc*100:.2f}%\")\n",
    "        print(f\"Val   loss: {val_loss:.4f} | Val   acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "        # Save best checkpoint\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            ckpt_path = os.path.join(args.save_dir, f\"fashion_cnn_acc{best_acc*100:.2f}_{timestamp}.pth\")\n",
    "            save_checkpoint(model, ckpt_path)\n",
    "\n",
    "    print(f\"\\nTraining finished. Best validation accuracy: {best_acc*100:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007471af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
