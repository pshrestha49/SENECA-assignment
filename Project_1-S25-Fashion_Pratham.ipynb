{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Training a Simple Neural Network with GPU\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, you will create, train, and evaluate a simple neural network using both TensorFlow and PyTorch. The objective is to ensure you are comfortable with setting up a neural network and utilizing GPU acceleration for training. \n",
    "\n",
    "The code for this assignment will mirror that of Lab 1, but you will need to complete some items, and make some changes.  You will use the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) for this project.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Set up TensorFlow and PyTorch environments.\n",
    "2. Verify GPU availability.\n",
    "3. Implement a simple neural network in TensorFlow and PyTorch.\n",
    "4. Train and evaluate the models.\n",
    "5. Answer assessment questions.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Follow the steps below to complete the project. Ensure that you use a GPU to train your models.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Set Up Your Environment\n",
    "\n",
    "First, install the necessary libraries. Run the following cell to install TensorFlow and PyTorch. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide snapshots from your environment showing:\n",
    "1) You are using a virtual environment\n",
    "2) You have installed `TensorFlow` and `PyTorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 2: Verify GPU Availability\n",
    "Check if TensorFlow and PyTorch can detect the GPU.\n",
    "\n",
    "Run the following two code blocks and show the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "GPU is available for TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(\"GPU is available for TensorFlow!\")\n",
    "else:\n",
    "    print(\"No GPU found for TensorFlow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "GPU is available for PyTorch!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available for PyTorch!\")\n",
    "elif torch.mps.is_available():\n",
    "    print(\"MPS (Apple Silicon GPU support) is available for PyTorch!\")\n",
    "else:\n",
    "    print(\"No GPU found for PyTorch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 3: Implement and Train a Simple Neural Network\n",
    "#### TensorFlow Implementation\n",
    "1. Load and preprocess the Fashion MNIST dataset.\n",
    "2. Define the neural network model.  Departing from the example in class, use 2 hidden layers, each with 64 units and relu activation functions, densely connected.\n",
    "3. Compile the model.\n",
    "4. Train the model using the GPU.  Use a batch size of 64, and run 6 epochs.\n",
    "5. Evaluate the model.\n",
    "\n",
    "You need to complete and run the code. Show the complete output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 22:47:08.434501: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-03 22:47:08.437684: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-03 22:47:08.439822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-03 22:47:08.567072: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-03 22:47:08.568198: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-03 22:47:08.569227: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-03 22:47:08.570193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4564 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 22:47:08.847762: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150528000 exceeds 10% of free system memory.\n",
      "2025-06-03 22:47:08.960419: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150528000 exceeds 10% of free system memory.\n",
      "2025-06-03 22:47:10.020873: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f64cf93f050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-06-03 22:47:10.020908: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2025-06-03 22:47:10.028702: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-03 22:47:10.061966: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8905\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749005230.136164    9996 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 5s 2ms/step - loss: 0.5308 - accuracy: 0.8151 - val_loss: 0.4239 - val_accuracy: 0.8493\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3867 - accuracy: 0.8608 - val_loss: 0.3763 - val_accuracy: 0.8620\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3481 - accuracy: 0.8712 - val_loss: 0.3666 - val_accuracy: 0.8669\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3206 - accuracy: 0.8819 - val_loss: 0.3387 - val_accuracy: 0.8762\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3052 - accuracy: 0.8865 - val_loss: 0.3424 - val_accuracy: 0.8748\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8690\n",
      "Test accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "fashion_mnist_data = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist_data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# with tf.device('/GPU:0'):\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Implementation\n",
    "1. Load and preprocess the Fashion MNIST dataset.  Set batch size to 64.\n",
    "2. Define the neural network model.  Departing from the example in class, use 2 hidden layers, each with 64 units and relu activation functions, densely connected.  \n",
    "4. Define loss function and optimizer.\n",
    "5. Train the model using the GPU.  Run 6 epochs.\n",
    "6. Evaluate the model.\n",
    "\n",
    "You need to complete and run the code. Show the complete output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 266kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:00<00:00, 4.94MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 4.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Epoch [1/6], Loss: 0.5069\n",
      "Epoch [2/6], Loss: 0.6438\n",
      "Epoch [3/6], Loss: 0.3031\n",
      "Epoch [4/6], Loss: 0.2903\n",
      "Epoch [5/6], Loss: 0.1610\n",
      "Epoch [6/6], Loss: 0.3480\n",
      "Test Accuracy: 87.33%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # 28x28 input flattened → 128 neurons\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Check for GPU\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "# Check for GPU\n",
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda'\n",
    "elif torch.mps.is_available():\n",
    "    dev = 'mps'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "device = torch.device(dev)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 6\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Questions\n",
    "Answer the following questions in detail.\n",
    "\n",
    "1. What is the purpose of normalizing the input data in both TensorFlow and PyTorch implementations?\n",
    "2. Explain the role of the activation function relu in the neural network.\n",
    "3. Why is it important to use GPU for training neural networks?\n",
    "4. Compare the training time and accuracy of the TensorFlow and PyTorch models. Which one performed better and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Answer:\n",
    "- The process of training neural networks becomes faster when inputs are on a similar level of scale.\n",
    "- The effect of gradients is smoother and more helpful when data has been normalized.\n",
    "- Shares out input values more evenly, so that no neuron is always recognized as the main one.\n",
    "- It helps avoid problems when gradients become too small or too large.\n",
    "- Better generalization and generally higher accuracy are often the result.\n",
    "- Helps make the process of optimization more effective.\n",
    "\n",
    "2. Answer:\n",
    "In other words, it provides neural networks with the ability to use data that is not linearly arranged.\n",
    "Very efficient to compute. Gradients are usually stronger in the positive range which prevents issues seen in other functions.\n",
    "By giving output 0 for negative inputs, logistic regression helps the model be more efficient and reliable.\n",
    "\n",
    "3. Answer:\n",
    "Processing thousands of operations all at once is possible in GPUs, making them excellent for deep learning calculations.\n",
    "GPUs are at least 10 times quicker than CPUs for most machine learning applications.\n",
    "Looking at it from the perspective of resources, faster computing leads to saving time and energy on results, so people can quickly try out ideas and test them out.\n",
    "Since deep learning models today have millions of parameters, training them would take days on a CPU, but with GPUs, this is achieved in hours.\n",
    "\n",
    "4. ANswer:\n",
    " - Training Time\n",
    "  TensorFlow trained significantly faster 10 sec compared to PyTorch 31 sec on this task. This is beacuse TensorFlow’s internal optimizations of various parameters.\n",
    "\n",
    "  - Accuracy\n",
    "  Both models achieved very similar accuracy , which is expected since the network architectures and training settings were nearly identical. PyTorch was slightly higher 87.11% than TensorFlow 86.90%, but this small difference is within the range of random variation for different training runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Submission\n",
    "Submit a link to your completed Jupyter Notebook (e.g., on GitHub (private) or Google Colab) with all the cells executed, and answers to the assessment questions included at the end of the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
