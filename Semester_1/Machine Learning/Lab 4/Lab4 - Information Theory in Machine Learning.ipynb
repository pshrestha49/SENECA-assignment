{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Information Theory in Machine Learning\n",
    "\n",
    "Welcome to this week's lab on Information Theory! This week, we will dive into the fascinating world of Information Theory as applied to Machine Learning. Specifically, we will focus on two key concepts: Entropy and Information Gain. These principles are fundamental in understanding how decision trees make split decisions to organize data effectively.\n",
    "\n",
    "### Entropy\n",
    "- Entropy, in the context of information theory, measures the level of uncertainty or disorder within a set of data.\n",
    "- In machine learning, particularly in decision trees, entropy helps to determine how a dataset should be split. A high entropy means more disorder, indicating that our dataset is varied. Conversely, low entropy suggests more uniformity in the data.\n",
    "\n",
    "### Information Gain\n",
    "- Information Gain measures the reduction in entropy after the dataset is split on an attribute.\n",
    "- It is crucial in building decision trees as it helps to decide the order of attributes the tree will use for splitting the data. The attribute with the highest Information Gain is chosen as the splitting attribute at each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Entropy and Information Gain in Decision Trees\n",
    "Decision Trees use these concepts to create branches. By choosing splits that maximize Information Gain (or equivalently minimize entropy), a decision tree can effectively categorize data, leading to better classification or regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load and Explore the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate Entropy\n",
    "To calculate the `entropy` we need to:\n",
    "- First, extract the target variable `y` from your dataset (like the 'target' column in the Iris dataset).\n",
    "- Then, call `calculate_entropy(y)` to get the entropy.\n",
    "\n",
    "This function calculates the entropy of a given target variable `y`. It works by first determining the unique classes in `y`, then computes the probability of each class, and uses this probability to calculate the entropy. This is a crucial step in understanding the disorder or uncertainty in the dataset, a fundamental concept in information theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(y):\n",
    "    class_labels = np.unique(y)\n",
    "    entropy = 0\n",
    "    for label in class_labels:\n",
    "        probability = len(y[y == label]) / len(y)\n",
    "        entropy -= probability * np.log2(probability)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the entropy for the target variable.  What is your observastion about the calculated Entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.584962500721156)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['target']\n",
    "entropy = calculate_entropy(y)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate Information Gain\n",
    "There are three steps for calculating the Information Gain:\n",
    "1. Compute Overall Entropy: Use the entropy function from Step 3 on the entire target dataset.\n",
    "2. Calculate Weighted Entropy for Each Attribute: For each unique value in the attribute, partition the dataset and calculate its entropy. Then calculate the weighted sum of these entropies, where the weights are the proportions of instances in each partition.\n",
    "3. Compute Information Gain: Subtract the weighted entropy of the split from the original entropy.\n",
    "\n",
    "The attribute with the highest Information Gain is generally chosen for splitting, as it provides the most significant reduction in uncertainty. This step is critical in constructing an effective decision tree, as it directly influences the structure and depth of the tree.\n",
    "\n",
    "**Use the provided function to calculate the information gain for each of the features in the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4463165236458\n",
      "1.4358978386754417\n",
      "0.8769376208910578\n",
      "0.5166428756804977\n"
     ]
    }
   ],
   "source": [
    "def calculate_information_gain(df, attribute, target_name):\n",
    "    total_entropy = calculate_entropy(df[target_name])\n",
    "    values, counts = np.unique(df[attribute], return_counts=True)\n",
    "    weighted_entropy = sum((counts[i] / sum(counts)) * calculate_entropy(df.where(df[attribute] == values[i]).dropna()[target_name]) for i in range(len(values)))\n",
    "    information_gain = total_entropy - weighted_entropy\n",
    "    return information_gain\n",
    "\n",
    "information_gain_sepal_length = calculate_information_gain(df, 'sepal length (cm)', 'target')\n",
    "information_gain_sepal_width = calculate_information_gain(df, 'sepal width (cm)', 'target')\n",
    "information_gain_petal_length = calculate_information_gain(df, 'petal length (cm)', 'target')\n",
    "information_gain_petal_width = calculate_information_gain(df, 'petal width (cm)', 'target')\n",
    "\n",
    "print(f'{information_gain_petal_length}\\n{information_gain_petal_width}\\n{information_gain_sepal_length}\\n{information_gain_sepal_width}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss your findings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSo we should choose the petal length for categorizing the dataset, since the information gain of the attribute is the highest.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "So we should choose the petal length for categorizing the dataset, since the information gain of the attribute is the highest.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Apply Entropy and Information Gain on a different dataset\n",
    "\n",
    "Your task is to choose a new dataset and implement what you learned in `Part 1` on this new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Implement Entropy and Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index_</th>\n",
       "      <th>Occurrence_Date</th>\n",
       "      <th>Occurrence_year</th>\n",
       "      <th>Occurrence_Month</th>\n",
       "      <th>Division</th>\n",
       "      <th>Hood_ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2004-01-03T05:00:00.000Z</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D53</td>\n",
       "      <td>98</td>\n",
       "      <td>Other</td>\n",
       "      <td>Rosedale-Moore Park (98)</td>\n",
       "      <td>43.685028</td>\n",
       "      <td>-79.392853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2004-01-08T05:00:00.000Z</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D42</td>\n",
       "      <td>137</td>\n",
       "      <td>Shooting</td>\n",
       "      <td>Woburn (137)</td>\n",
       "      <td>43.781536</td>\n",
       "      <td>-79.234962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2004-01-08T05:00:00.000Z</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D42</td>\n",
       "      <td>132</td>\n",
       "      <td>Shooting</td>\n",
       "      <td>Malvern (132)</td>\n",
       "      <td>43.810860</td>\n",
       "      <td>-79.206894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2004-01-25T05:00:00.000Z</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D13</td>\n",
       "      <td>93</td>\n",
       "      <td>Shooting</td>\n",
       "      <td>Dovercourt-Wallace Emerson-Junction (93)</td>\n",
       "      <td>43.670475</td>\n",
       "      <td>-79.434403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2004-01-25T05:00:00.000Z</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D42</td>\n",
       "      <td>131</td>\n",
       "      <td>Shooting</td>\n",
       "      <td>Rouge (131)</td>\n",
       "      <td>43.823543</td>\n",
       "      <td>-79.203865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168535</th>\n",
       "      <td>179392</td>\n",
       "      <td>2018-05-16T20:30:00.000Z</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>May</td>\n",
       "      <td>D54</td>\n",
       "      <td>43</td>\n",
       "      <td>Auto Theft</td>\n",
       "      <td>Victoria Village (43)</td>\n",
       "      <td>43.718910</td>\n",
       "      <td>-79.304466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168536</th>\n",
       "      <td>179393</td>\n",
       "      <td>2018-05-24T18:00:00.000Z</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>May</td>\n",
       "      <td>D55</td>\n",
       "      <td>62</td>\n",
       "      <td>Auto Theft</td>\n",
       "      <td>East End-Danforth (62)</td>\n",
       "      <td>43.684856</td>\n",
       "      <td>-79.297562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168537</th>\n",
       "      <td>179394</td>\n",
       "      <td>2018-05-24T19:00:00.000Z</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>May</td>\n",
       "      <td>D41</td>\n",
       "      <td>122</td>\n",
       "      <td>Auto Theft</td>\n",
       "      <td>Birchcliffe-Cliffside (122)</td>\n",
       "      <td>43.685402</td>\n",
       "      <td>-79.274391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168538</th>\n",
       "      <td>179395</td>\n",
       "      <td>2018-05-24T17:00:00.000Z</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>May</td>\n",
       "      <td>D23</td>\n",
       "      <td>1</td>\n",
       "      <td>Auto Theft</td>\n",
       "      <td>West Humber-Clairville (1)</td>\n",
       "      <td>43.686760</td>\n",
       "      <td>-79.595566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168539</th>\n",
       "      <td>179396</td>\n",
       "      <td>2018-05-22T09:00:00.000Z</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>May</td>\n",
       "      <td>D32</td>\n",
       "      <td>27</td>\n",
       "      <td>Auto Theft</td>\n",
       "      <td>York University Heights (27)</td>\n",
       "      <td>43.775364</td>\n",
       "      <td>-79.481178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168540 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Index_           Occurrence_Date  Occurrence_year Occurrence_Month  \\\n",
       "0            1  2004-01-03T05:00:00.000Z           2004.0              NaN   \n",
       "1            2  2004-01-08T05:00:00.000Z           2004.0              NaN   \n",
       "2            3  2004-01-08T05:00:00.000Z           2004.0              NaN   \n",
       "3            4  2004-01-25T05:00:00.000Z           2004.0              NaN   \n",
       "4            5  2004-01-25T05:00:00.000Z           2004.0              NaN   \n",
       "...        ...                       ...              ...              ...   \n",
       "168535  179392  2018-05-16T20:30:00.000Z           2018.0              May   \n",
       "168536  179393  2018-05-24T18:00:00.000Z           2018.0              May   \n",
       "168537  179394  2018-05-24T19:00:00.000Z           2018.0              May   \n",
       "168538  179395  2018-05-24T17:00:00.000Z           2018.0              May   \n",
       "168539  179396  2018-05-22T09:00:00.000Z           2018.0              May   \n",
       "\n",
       "       Division  Hood_ID        Type  \\\n",
       "0           D53       98       Other   \n",
       "1           D42      137    Shooting   \n",
       "2           D42      132    Shooting   \n",
       "3           D13       93    Shooting   \n",
       "4           D42      131    Shooting   \n",
       "...         ...      ...         ...   \n",
       "168535      D54       43  Auto Theft   \n",
       "168536      D55       62  Auto Theft   \n",
       "168537      D41      122  Auto Theft   \n",
       "168538      D23        1  Auto Theft   \n",
       "168539      D32       27  Auto Theft   \n",
       "\n",
       "                                   Neighbourhood        Lat       Long  \n",
       "0                       Rosedale-Moore Park (98)  43.685028 -79.392853  \n",
       "1                                   Woburn (137)  43.781536 -79.234962  \n",
       "2                                  Malvern (132)  43.810860 -79.206894  \n",
       "3       Dovercourt-Wallace Emerson-Junction (93)  43.670475 -79.434403  \n",
       "4                                    Rouge (131)  43.823543 -79.203865  \n",
       "...                                          ...        ...        ...  \n",
       "168535                     Victoria Village (43)  43.718910 -79.304466  \n",
       "168536                    East End-Danforth (62)  43.684856 -79.297562  \n",
       "168537               Birchcliffe-Cliffside (122)  43.685402 -79.274391  \n",
       "168538                West Humber-Clairville (1)  43.686760 -79.595566  \n",
       "168539              York University Heights (27)  43.775364 -79.481178  \n",
       "\n",
       "[168540 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "toronto_mci = pd.read_csv('mci.csv')\n",
    "mci_y = toronto_mci['Type']\n",
    "mci_entropy = calculate_entropy(mci_y)\n",
    "toronto_mci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mci_occ_date_information_gain \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_information_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoronto_mci\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOccurrence_Date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mType\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmci_occ_date_information_gain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# mci_occ_year_information_gain = calculate_information_gain(toronto_mci, 'Occurrence_year', 'Type')\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# mci_occ_month_information_gain = calculate_information_gain(toronto_mci, 'Occurrence_Month', 'Type')\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# mci_division_information_gain = calculate_information_gain(toronto_mci, 'Division', 'Type')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(f'{mci_occ_date_information_gain}\\n{mci_occ_year_information_gain}\\n{mci_occ_month_information_gain}\\n{mci_division_information_gain}\\n{mci_hood_id_information_gain}\\n{mci_neighbourhood_information_gain}\\n{mci_lat_information_gain}\\n{mci_long_information_gain}')\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36mcalculate_information_gain\u001b[1;34m(df, attribute, target_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m total_entropy \u001b[38;5;241m=\u001b[39m calculate_entropy(df[target_name])\n\u001b[0;32m      3\u001b[0m values, counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(df[attribute], return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m weighted_entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcalculate_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m information_gain \u001b[38;5;241m=\u001b[39m total_entropy \u001b[38;5;241m-\u001b[39m weighted_entropy\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m information_gain\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m total_entropy \u001b[38;5;241m=\u001b[39m calculate_entropy(df[target_name])\n\u001b[0;32m      3\u001b[0m values, counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(df[attribute], return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m weighted_entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((counts[i] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(counts)) \u001b[38;5;241m*\u001b[39m calculate_entropy(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()[target_name]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(values)))\n\u001b[0;32m      5\u001b[0m information_gain \u001b[38;5;241m=\u001b[39m total_entropy \u001b[38;5;241m-\u001b[39m weighted_entropy\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m information_gain\n",
      "File \u001b[1;32mc:\\Users\\W1tcher\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py:10984\u001b[0m, in \u001b[0;36mNDFrame.where\u001b[1;34m(self, cond, other, inplace, axis, level)\u001b[0m\n\u001b[0;32m  10977\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m  10978\u001b[0m                 _chained_assignment_warning_method_msg,\n\u001b[0;32m  10979\u001b[0m                 \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m  10980\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m  10981\u001b[0m             )\n\u001b[0;32m  10983\u001b[0m other \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mapply_if_callable(other, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m> 10984\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_where\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\W1tcher\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\generic.py:10759\u001b[0m, in \u001b[0;36mNDFrame._where\u001b[1;34m(self, cond, other, inplace, axis, level, warn)\u001b[0m\n\u001b[0;32m  10756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(result)\n\u001b[0;32m  10758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 10759\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10762\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10763\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10764\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m  10765\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\W1tcher\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:204\u001b[0m, in \u001b[0;36mDataManager.where\u001b[1;34m(self, other, cond, align)\u001b[0m\n\u001b[0;32m    201\u001b[0m     align_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    202\u001b[0m     other \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43malign_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\W1tcher\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\W1tcher\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1634\u001b[0m, in \u001b[0;36mBlock.where\u001b[1;34m(self, other, cond, _downcast, using_cow)\u001b[0m\n\u001b[0;32m   1629\u001b[0m             other \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(other)\u001b[38;5;241m.\u001b[39mreshape(values\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1630\u001b[0m             \u001b[38;5;66;03m# If lengths don't match (or len(other)==1), we will raise\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m             \u001b[38;5;66;03m#  inside expressions.where, see test_series_where\u001b[39;00m\n\u001b[0;32m   1632\u001b[0m \n\u001b[0;32m   1633\u001b[0m         \u001b[38;5;66;03m# Note: expressions.where may upcast.\u001b[39;00m\n\u001b[1;32m-> 1634\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mexpressions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43micond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1635\u001b[0m         \u001b[38;5;66;03m# The np_can_hold_element check _should_ ensure that we always\u001b[39;00m\n\u001b[0;32m   1636\u001b[0m         \u001b[38;5;66;03m#  have result.dtype == self.dtype here.\u001b[39;00m\n\u001b[0;32m   1638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transpose:\n",
      "File \u001b[1;32mc:\\Users\\W1tcher\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:259\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(cond, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mEvaluate the where condition cond on a and b.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    Whether to try to use numexpr.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m _where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_where\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m use_numexpr \u001b[38;5;28;01melse\u001b[39;00m _where_standard(cond, a, b)\n",
      "File \u001b[1;32mc:\\Users\\W1tcher\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:189\u001b[0m, in \u001b[0;36m_where_numexpr\u001b[1;34m(cond, a, b)\u001b[0m\n\u001b[0;32m    182\u001b[0m     result \u001b[38;5;241m=\u001b[39m ne\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhere(cond_value, a_value, b_value)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    184\u001b[0m         local_dict\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond_value\u001b[39m\u001b[38;5;124m\"\u001b[39m: cond, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma_value\u001b[39m\u001b[38;5;124m\"\u001b[39m: a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb_value\u001b[39m\u001b[38;5;124m\"\u001b[39m: b},\n\u001b[0;32m    185\u001b[0m         casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_where_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\W1tcher\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:174\u001b[0m, in \u001b[0;36m_where_standard\u001b[1;34m(cond, a, b)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_where_standard\u001b[39m(cond, a, b):\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for extracting ndarray if necessary\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mci_occ_date_information_gain = calculate_information_gain(toronto_mci, 'Occurrence_Date', 'Type')\n",
    "print(f'{mci_occ_date_information_gain}')\n",
    "# mci_occ_year_information_gain = calculate_information_gain(toronto_mci, 'Occurrence_year', 'Type')\n",
    "# mci_occ_month_information_gain = calculate_information_gain(toronto_mci, 'Occurrence_Month', 'Type')\n",
    "# mci_division_information_gain = calculate_information_gain(toronto_mci, 'Division', 'Type')\n",
    "# mci_hood_id_information_gain = calculate_information_gain(toronto_mci, 'Hood_ID', 'Type')\n",
    "# mci_neighbourhood_information_gain = calculate_information_gain(toronto_mci, 'Neighbourhood', 'Type')\n",
    "# mci_lat_information_gain = calculate_information_gain(toronto_mci, 'Lat', 'Type')\n",
    "# mci_long_information_gain = calculate_information_gain(toronto_mci, 'Long', 'Type')\n",
    "\n",
    "# print(f'{mci_occ_date_information_gain}\\n{mci_occ_year_information_gain}\\n{mci_occ_month_information_gain}\\n{mci_division_information_gain}\\n{mci_hood_id_information_gain}\\n{mci_neighbourhood_information_gain}\\n{mci_lat_information_gain}\\n{mci_long_information_gain}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Discuss your findings in detail\n",
    "Provide detailed explanation and discussion about your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Submit your completed Jupyter Notebook file through the submission link in Blackboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
