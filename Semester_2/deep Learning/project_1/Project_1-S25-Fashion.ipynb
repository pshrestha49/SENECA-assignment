{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Training a Simple Neural Network with GPU\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, you will create, train, and evaluate a simple neural network using both TensorFlow and PyTorch. The objective is to ensure you are comfortable with setting up a neural network and utilizing GPU acceleration for training. \n",
    "\n",
    "The code for this assignment will mirror that of Lab 1, but you will need to complete some items, and make some changes.  You will use the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) for this project.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Set up TensorFlow and PyTorch environments.\n",
    "2. Verify GPU availability.\n",
    "3. Implement a simple neural network in TensorFlow and PyTorch.\n",
    "4. Train and evaluate the models.\n",
    "5. Answer assessment questions.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Follow the steps below to complete the project. Ensure that you use a GPU to train your models.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Set Up Your Environment\n",
    "\n",
    "First, install the necessary libraries. Run the following cell to install TensorFlow and PyTorch. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide snapshots from your environment showing:\n",
    "1) You are using a virtual environment\n",
    "2) You have installed `TensorFlow` and `PyTorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 2: Verify GPU Availability\n",
    "Check if TensorFlow and PyTorch can detect the GPU.\n",
    "\n",
    "Run the following two code blocks and show the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.12.0\n",
      "GPU is available for TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(\"GPU is available for TensorFlow!\")\n",
    "else:\n",
    "    print(\"No GPU found for TensorFlow.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu118\n",
      "GPU is available for PyTorch!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available for PyTorch!\")\n",
    "elif torch.mps.is_available():\n",
    "    print(\"MPS (Apple Silicon GPU support) is available for PyTorch!\")\n",
    "else:\n",
    "    print(\"No GPU found for PyTorch.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 3: Implement and Train a Simple Neural Network\n",
    "#### TensorFlow Implementation\n",
    "1. Load and preprocess the Fashion MNIST dataset.\n",
    "2. Define the neural network model.  Departing from the example in class, use 2 hidden layers, each with 64 units and relu activation functions, densely connected.\n",
    "3. Compile the model.\n",
    "4. Train the model using the GPU.  Use a batch size of 64, and run 6 epochs.\n",
    "5. Evaluate the model.\n",
    "\n",
    "You need to complete and run the code. Show the complete output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 3s 2ms/step - loss: 0.5535 - accuracy: 0.8114\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4130 - accuracy: 0.8565\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3745 - accuracy: 0.8674\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3500 - accuracy: 0.8763\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3324 - accuracy: 0.8800\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3717 - accuracy: 0.8682\n",
      "Test accuracy: 0.8682\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def print_free_ram(step=\"\"):\n",
    "    ram = psutil.virtual_memory()\n",
    "    print(f\"[{step}] Free RAM: {ram.available / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "# Track RAM after imports\n",
    "# print_free_ram(\"After imports\")\n",
    "\n",
    "# Load and preprocess dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "# print_free_ram(\"After data preprocessing\")\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "# print_free_ram(\"After model definition\")\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# print_free_ram(\"After model compile\")\n",
    "\n",
    "# Train model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)\n",
    "# print_free_ram(\"After training\")\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "# print_free_ram(\"After evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Implementation\n",
    "1. Load and preprocess the Fashion MNIST dataset.  Set batch size to 64.\n",
    "2. Define the neural network model.  Departing from the example in class, use 2 hidden layers, each with 64 units and relu activation functions, densely connected.  \n",
    "4. Define loss function and optimizer.\n",
    "5. Train the model using the GPU.  Run 6 epochs.\n",
    "6. Evaluate the model.\n",
    "\n",
    "You need to complete and run the code. Show the complete output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Loss: 0.4691\n",
      "Epoch [2/6], Loss: 0.1514\n",
      "Epoch [3/6], Loss: 0.3949\n",
      "Epoch [4/6], Loss: 0.2682\n",
      "Epoch [5/6], Loss: 0.2422\n",
      "Epoch [6/6], Loss: 0.1963\n",
      "Test Accuracy: 87.03%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # 28x28 input flattened â†’ 128 neurons\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Check for GPU\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "# Check for GPU\n",
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda'\n",
    "elif torch.mps.is_available():\n",
    "    dev = 'mps'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "device = torch.device(dev)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 6\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total    \n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Questions\n",
    "Answer the following questions in detail.\n",
    "\n",
    "1. What is the purpose of normalizing the input data in both TensorFlow and PyTorch implementations?\n",
    "2. Explain the role of the activation function relu in the neural network.\n",
    "3. Why is it important to use GPU for training neural networks?\n",
    "4. Compare the training time and accuracy of the TensorFlow and PyTorch models. Which one performed better and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Submission\n",
    "Submit a link to your completed Jupyter Notebook (e.g., on GitHub (private) or Google Colab) with all the cells executed, and answers to the assessment questions included at the end of the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
